{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from graphviz import Digraph\n",
        "\n",
        "dot = Digraph(\"MLflow_Structure\", format=\"png\")\n",
        "dot.attr(rankdir=\"TB\", splines=\"spline\", nodesep=\"0.8\", ranksep=\"1.0\", bgcolor=\"white\")\n",
        "\n",
        "# Root\n",
        "dot.node(\"mlflow\", \"üöÄ MLflow\", shape=\"oval\", style=\"filled\", fillcolor=\"#c7d2fe\")\n",
        "\n",
        "# Left: Tracking\n",
        "dot.node(\"tracking\", \"üìä MLflow Tracking\", shape=\"box\", style=\"filled\", fillcolor=\"#dbeafe\")\n",
        "dot.node(\"exp\", \"üóÇÔ∏è Experiments\", shape=\"box\")\n",
        "dot.node(\"run1\", \"‚ñ∂Ô∏è Run 1\", shape=\"folder\", style=\"rounded\")\n",
        "dot.node(\"run2\", \"‚ñ∂Ô∏è Run 2\", shape=\"folder\", style=\"rounded\")\n",
        "\n",
        "# Run 1 internals\n",
        "dot.node(\"metrics1\", \"üìà Metrics\", shape=\"note\")\n",
        "dot.node(\"params1\", \"‚öôÔ∏è Params\", shape=\"note\")\n",
        "dot.node(\"artifact1\", \"üìÅ Artifact:\\nmodel.pkl\", shape=\"note\", style=\"filled\", fillcolor=\"#fef9c3\")\n",
        "\n",
        "# Right: Model Registry\n",
        "dot.node(\"registry\", \"üì¶ MLflow Model Registry\", shape=\"box\", style=\"filled\", fillcolor=\"#fde68a\")\n",
        "dot.node(\"reg_models\", \"üóÉÔ∏è Registered Models\", shape=\"box\")\n",
        "dot.node(\"versions\", \"üî¢ Model Versions\", shape=\"box\")\n",
        "dot.node(\"v1\", \"v1 (from Run 1)\", shape=\"folder\", style=\"rounded\")\n",
        "dot.node(\"v2\", \"v2 (from Run 2)\", shape=\"folder\", style=\"rounded\")\n",
        "dot.node(\"stages\", \"‚õìÔ∏è Stages:\\nNone ‚Üí Staging ‚Üí Production ‚Üí Archived\", shape=\"note\")\n",
        "\n",
        "# Top-level connections\n",
        "dot.edge(\"mlflow\", \"tracking\", label=\"Tracking ML experiments\")\n",
        "dot.edge(\"mlflow\", \"registry\", label=\"Manage and deploy models\")\n",
        "\n",
        "# Left branch connections\n",
        "dot.edge(\"tracking\", \"exp\")\n",
        "dot.edge(\"exp\", \"run1\")\n",
        "dot.edge(\"exp\", \"run2\")\n",
        "dot.edge(\"run1\", \"metrics1\")\n",
        "dot.edge(\"run1\", \"params1\")\n",
        "dot.edge(\"run1\", \"artifact1\")\n",
        "\n",
        "# Artifact connects to Registry\n",
        "dot.edge(\"artifact1\", \"reg_models\", label=\"mlflow.register_model()\", style=\"dashed\", color=\"blue\",constraint=\"false\")\n",
        "\n",
        "# Right branch connections\n",
        "dot.edge(\"registry\", \"reg_models\")\n",
        "dot.edge(\"reg_models\", \"versions\")\n",
        "dot.edge(\"versions\", \"v1\")\n",
        "dot.edge(\"versions\", \"v2\")\n",
        "dot.edge(\"versions\", \"stages\")\n",
        "\n",
        "dot\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 703
        },
        "id": "FgYrqIJBo6C5",
        "outputId": "66984660-b50a-428d-eb81-fac79bfd1d97"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: MLflow_Structure Pages: 1 -->\n<svg width=\"1090pt\" height=\"496pt\"\n viewBox=\"0.00 0.00 1089.50 496.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 492)\">\n<title>MLflow_Structure</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-492 1085.5,-492 1085.5,4 -4,4\"/>\n<!-- mlflow -->\n<g id=\"node1\" class=\"node\">\n<title>mlflow</title>\n<ellipse fill=\"#c7d2fe\" stroke=\"black\" cx=\"411\" cy=\"-470\" rx=\"55.79\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"411\" y=\"-466.3\" font-family=\"Times,serif\" font-size=\"14.00\">üöÄ MLflow</text>\n</g>\n<!-- tracking -->\n<g id=\"node2\" class=\"node\">\n<title>tracking</title>\n<polygon fill=\"#dbeafe\" stroke=\"black\" points=\"372.5,-365 235.5,-365 235.5,-329 372.5,-329 372.5,-365\"/>\n<text text-anchor=\"middle\" x=\"304\" y=\"-343.3\" font-family=\"Times,serif\" font-size=\"14.00\">üìä MLflow Tracking</text>\n</g>\n<!-- mlflow&#45;&gt;tracking -->\n<g id=\"edge1\" class=\"edge\">\n<title>mlflow&#45;&gt;tracking</title>\n<path fill=\"none\" stroke=\"black\" d=\"M365.19,-459.68C341.07,-452.2 313.56,-438.99 299,-416 291.41,-404 292.02,-388.32 294.83,-375.04\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"298.3,-375.58 297.43,-365.02 291.53,-373.82 298.3,-375.58\"/>\n<text text-anchor=\"middle\" x=\"371.5\" y=\"-404.8\" font-family=\"Times,serif\" font-size=\"14.00\">Tracking ML experiments</text>\n</g>\n<!-- registry -->\n<g id=\"node9\" class=\"node\">\n<title>registry</title>\n<polygon fill=\"#fde68a\" stroke=\"black\" points=\"605.5,-365 430.5,-365 430.5,-329 605.5,-329 605.5,-365\"/>\n<text text-anchor=\"middle\" x=\"518\" y=\"-343.3\" font-family=\"Times,serif\" font-size=\"14.00\">üì¶ MLflow Model Registry</text>\n</g>\n<!-- mlflow&#45;&gt;registry -->\n<g id=\"edge2\" class=\"edge\">\n<title>mlflow&#45;&gt;registry</title>\n<path fill=\"none\" stroke=\"black\" d=\"M425.88,-452.18C444.14,-431.52 475.26,-396.33 496.22,-372.63\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"498.9,-374.88 502.9,-365.07 493.66,-370.24 498.9,-374.88\"/>\n<text text-anchor=\"middle\" x=\"546\" y=\"-404.8\" font-family=\"Times,serif\" font-size=\"14.00\">Manage and deploy models</text>\n</g>\n<!-- exp -->\n<g id=\"node3\" class=\"node\">\n<title>exp</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"358.5,-256 249.5,-256 249.5,-220 358.5,-220 358.5,-256\"/>\n<text text-anchor=\"middle\" x=\"304\" y=\"-234.3\" font-family=\"Times,serif\" font-size=\"14.00\">üóÇÔ∏è Experiments</text>\n</g>\n<!-- tracking&#45;&gt;exp -->\n<g id=\"edge3\" class=\"edge\">\n<title>tracking&#45;&gt;exp</title>\n<path fill=\"none\" stroke=\"black\" d=\"M304,-328.81C304,-311.96 304,-286.02 304,-266.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"307.5,-266.15 304,-256.15 300.5,-266.15 307.5,-266.15\"/>\n</g>\n<!-- run1 -->\n<g id=\"node4\" class=\"node\">\n<title>run1</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"212,-147 209,-151 188,-151 185,-147 144,-147 144,-111 212,-111 212,-147\"/>\n<text text-anchor=\"middle\" x=\"178\" y=\"-125.3\" font-family=\"Times,serif\" font-size=\"14.00\">‚ñ∂Ô∏è Run 1</text>\n</g>\n<!-- exp&#45;&gt;run1 -->\n<g id=\"edge4\" class=\"edge\">\n<title>exp&#45;&gt;run1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M283.76,-219.81C262.72,-201.95 229.65,-173.86 206.09,-153.86\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"208.08,-150.95 198.19,-147.15 203.55,-156.29 208.08,-150.95\"/>\n</g>\n<!-- run2 -->\n<g id=\"node5\" class=\"node\">\n<title>run2</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"338,-147 335,-151 314,-151 311,-147 270,-147 270,-111 338,-111 338,-147\"/>\n<text text-anchor=\"middle\" x=\"304\" y=\"-125.3\" font-family=\"Times,serif\" font-size=\"14.00\">‚ñ∂Ô∏è Run 2</text>\n</g>\n<!-- exp&#45;&gt;run2 -->\n<g id=\"edge5\" class=\"edge\">\n<title>exp&#45;&gt;run2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M304,-219.81C304,-202.96 304,-177.02 304,-157.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"307.5,-157.15 304,-147.15 300.5,-157.15 307.5,-157.15\"/>\n</g>\n<!-- metrics1 -->\n<g id=\"node6\" class=\"node\">\n<title>metrics1</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"76,-37 0,-37 0,-1 82,-1 82,-31 76,-37\"/>\n<polyline fill=\"none\" stroke=\"black\" points=\"76,-37 76,-31 \"/>\n<polyline fill=\"none\" stroke=\"black\" points=\"82,-31 76,-31 \"/>\n<text text-anchor=\"middle\" x=\"41\" y=\"-15.3\" font-family=\"Times,serif\" font-size=\"14.00\">üìà Metrics</text>\n</g>\n<!-- run1&#45;&gt;metrics1 -->\n<g id=\"edge6\" class=\"edge\">\n<title>run1&#45;&gt;metrics1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M156.29,-110.89C133.14,-92.64 96.34,-63.63 70.56,-43.3\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"72.63,-40.48 62.61,-37.03 68.29,-45.97 72.63,-40.48\"/>\n</g>\n<!-- params1 -->\n<g id=\"node7\" class=\"node\">\n<title>params1</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"209.5,-37 140.5,-37 140.5,-1 215.5,-1 215.5,-31 209.5,-37\"/>\n<polyline fill=\"none\" stroke=\"black\" points=\"209.5,-37 209.5,-31 \"/>\n<polyline fill=\"none\" stroke=\"black\" points=\"215.5,-31 209.5,-31 \"/>\n<text text-anchor=\"middle\" x=\"178\" y=\"-15.3\" font-family=\"Times,serif\" font-size=\"14.00\">‚öôÔ∏è Params</text>\n</g>\n<!-- run1&#45;&gt;params1 -->\n<g id=\"edge7\" class=\"edge\">\n<title>run1&#45;&gt;params1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M178,-110.65C178,-93.56 178,-67.22 178,-47.32\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"181.5,-47.31 178,-37.31 174.5,-47.31 181.5,-47.31\"/>\n</g>\n<!-- artifact1 -->\n<g id=\"node8\" class=\"node\">\n<title>artifact1</title>\n<polygon fill=\"#fef9c3\" stroke=\"black\" points=\"352.5,-38 273.5,-38 273.5,0 358.5,0 358.5,-32 352.5,-38\"/>\n<polyline fill=\"none\" stroke=\"black\" points=\"352.5,-38 352.5,-32 \"/>\n<polyline fill=\"none\" stroke=\"black\" points=\"358.5,-32 352.5,-32 \"/>\n<text text-anchor=\"middle\" x=\"316\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\">üìÅ Artifact:</text>\n<text text-anchor=\"middle\" x=\"316\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\">model.pkl</text>\n</g>\n<!-- run1&#45;&gt;artifact1 -->\n<g id=\"edge8\" class=\"edge\">\n<title>run1&#45;&gt;artifact1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M199.87,-110.89C222.77,-92.96 258.95,-64.65 284.84,-44.39\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"287.14,-47.03 292.85,-38.11 282.82,-41.52 287.14,-47.03\"/>\n</g>\n<!-- reg_models -->\n<g id=\"node10\" class=\"node\">\n<title>reg_models</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"610.5,-256 467.5,-256 467.5,-220 610.5,-220 610.5,-256\"/>\n<text text-anchor=\"middle\" x=\"539\" y=\"-234.3\" font-family=\"Times,serif\" font-size=\"14.00\">üóÉÔ∏è Registered Models</text>\n</g>\n<!-- artifact1&#45;&gt;reg_models -->\n<g id=\"edge9\" class=\"edge\">\n<title>artifact1&#45;&gt;reg_models</title>\n<path fill=\"none\" stroke=\"blue\" stroke-dasharray=\"5,2\" d=\"M334.67,-38.16C374.76,-77.18 469.13,-169.01 514.19,-212.86\"/>\n<polygon fill=\"blue\" stroke=\"blue\" points=\"511.89,-215.51 521.5,-219.97 516.78,-210.49 511.89,-215.51\"/>\n<text text-anchor=\"middle\" x=\"513\" y=\"-125.3\" font-family=\"Times,serif\" font-size=\"14.00\">mlflow.register_model()</text>\n</g>\n<!-- registry&#45;&gt;reg_models -->\n<g id=\"edge10\" class=\"edge\">\n<title>registry&#45;&gt;reg_models</title>\n<path fill=\"none\" stroke=\"black\" d=\"M521.37,-328.81C524.7,-311.88 529.82,-285.78 533.69,-266.07\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"537.14,-266.64 535.63,-256.15 530.27,-265.29 537.14,-266.64\"/>\n</g>\n<!-- versions -->\n<g id=\"node11\" class=\"node\">\n<title>versions</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"771.5,-147 646.5,-147 646.5,-111 771.5,-111 771.5,-147\"/>\n<text text-anchor=\"middle\" x=\"709\" y=\"-125.3\" font-family=\"Times,serif\" font-size=\"14.00\">üî¢ Model Versions</text>\n</g>\n<!-- reg_models&#45;&gt;versions -->\n<g id=\"edge11\" class=\"edge\">\n<title>reg_models&#45;&gt;versions</title>\n<path fill=\"none\" stroke=\"black\" d=\"M566.31,-219.81C595.31,-201.56 641.27,-172.63 673.16,-152.56\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"675.16,-155.44 681.75,-147.15 671.43,-149.51 675.16,-155.44\"/>\n</g>\n<!-- v1 -->\n<g id=\"node12\" class=\"node\">\n<title>v1</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"597.5,-37 594.5,-41 573.5,-41 570.5,-37 490.5,-37 490.5,-1 597.5,-1 597.5,-37\"/>\n<text text-anchor=\"middle\" x=\"544\" y=\"-15.3\" font-family=\"Times,serif\" font-size=\"14.00\">v1 (from Run 1)</text>\n</g>\n<!-- versions&#45;&gt;v1 -->\n<g id=\"edge12\" class=\"edge\">\n<title>versions&#45;&gt;v1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M682.86,-110.89C654.61,-92.4 609.5,-62.87 578.4,-42.51\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"580.31,-39.58 570.02,-37.03 576.47,-45.44 580.31,-39.58\"/>\n</g>\n<!-- v2 -->\n<g id=\"node13\" class=\"node\">\n<title>v2</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"762.5,-37 759.5,-41 738.5,-41 735.5,-37 655.5,-37 655.5,-1 762.5,-1 762.5,-37\"/>\n<text text-anchor=\"middle\" x=\"709\" y=\"-15.3\" font-family=\"Times,serif\" font-size=\"14.00\">v2 (from Run 2)</text>\n</g>\n<!-- versions&#45;&gt;v2 -->\n<g id=\"edge13\" class=\"edge\">\n<title>versions&#45;&gt;v2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M709,-110.65C709,-93.56 709,-67.22 709,-47.32\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"712.5,-47.31 709,-37.31 705.5,-47.31 712.5,-47.31\"/>\n</g>\n<!-- stages -->\n<g id=\"node14\" class=\"node\">\n<title>stages</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"1075.5,-38 820.5,-38 820.5,0 1081.5,0 1081.5,-32 1075.5,-38\"/>\n<polyline fill=\"none\" stroke=\"black\" points=\"1075.5,-38 1075.5,-32 \"/>\n<polyline fill=\"none\" stroke=\"black\" points=\"1081.5,-32 1075.5,-32 \"/>\n<text text-anchor=\"middle\" x=\"951\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\">‚õìÔ∏è Stages:</text>\n<text text-anchor=\"middle\" x=\"951\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\">None ‚Üí Staging ‚Üí Production ‚Üí Archived</text>\n</g>\n<!-- versions&#45;&gt;stages -->\n<g id=\"edge14\" class=\"edge\">\n<title>versions&#45;&gt;stages</title>\n<path fill=\"none\" stroke=\"black\" d=\"M747.35,-110.89C788.9,-92.34 855.38,-62.67 901.01,-42.31\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"902.71,-45.39 910.41,-38.11 899.85,-38.99 902.71,-45.39\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.graphs.Digraph at 0x7f147e66bf20>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "EJJEupoDsx5I",
        "outputId": "08d1dc7b-af03-4209-f687-d2aae14f316d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mlflow==2.14.1 in /usr/local/lib/python3.12/dist-packages (2.14.1)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.12/dist-packages (from mlflow==2.14.1) (3.1.2)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.12/dist-packages (from mlflow==2.14.1) (1.17.1)\n",
            "Requirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow==2.14.1) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow==2.14.1) (8.3.0)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.12/dist-packages (from mlflow==2.14.1) (3.1.2)\n",
            "Requirement already satisfied: docker<8,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow==2.14.1) (7.1.0)\n",
            "Requirement already satisfied: entrypoints<1 in /usr/local/lib/python3.12/dist-packages (from mlflow==2.14.1) (0.4)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.12/dist-packages (from mlflow==2.14.1) (3.1.45)\n",
            "Requirement already satisfied: graphene<4 in /usr/local/lib/python3.12/dist-packages (from mlflow==2.14.1) (3.4.3)\n",
            "Requirement already satisfied: importlib-metadata!=4.7.0,<8,>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow==2.14.1) (7.2.1)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.12/dist-packages (from mlflow==2.14.1) (3.10)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.12/dist-packages (from mlflow==2.14.1) (3.10.0)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.12/dist-packages (from mlflow==2.14.1) (1.26.4)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow==2.14.1) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow==2.14.1) (1.37.0)\n",
            "Requirement already satisfied: packaging<25 in /usr/local/lib/python3.12/dist-packages (from mlflow==2.14.1) (24.2)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.12/dist-packages (from mlflow==2.14.1) (2.2.2)\n",
            "Requirement already satisfied: protobuf<5,>=3.12.0 in /usr/local/lib/python3.12/dist-packages (from mlflow==2.14.1) (4.25.8)\n",
            "Requirement already satisfied: pyarrow<16,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow==2.14.1) (15.0.2)\n",
            "Requirement already satisfied: pytz<2025 in /usr/local/lib/python3.12/dist-packages (from mlflow==2.14.1) (2024.2)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.12/dist-packages (from mlflow==2.14.1) (6.0.3)\n",
            "Requirement already satisfied: querystring-parser<2 in /usr/local/lib/python3.12/dist-packages (from mlflow==2.14.1) (1.2.4)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.12/dist-packages (from mlflow==2.14.1) (2.32.4)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.12/dist-packages (from mlflow==2.14.1) (1.6.1)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.12/dist-packages (from mlflow==2.14.1) (1.16.3)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow==2.14.1) (2.0.44)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow==2.14.1) (0.5.3)\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.12/dist-packages (from mlflow==2.14.1) (3.1.6)\n",
            "Requirement already satisfied: gunicorn<23 in /usr/local/lib/python3.12/dist-packages (from mlflow==2.14.1) (22.0.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic!=1.10.0,<2->mlflow==2.14.1) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic!=1.10.0,<2->mlflow==2.14.1) (4.15.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from docker<8,>=4.0.0->mlflow==2.14.1) (2.5.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow==2.14.1) (1.9.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow==2.14.1) (2.2.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow==2.14.1) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow==2.14.1) (3.1.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython<4,>=3.1.9->mlflow==2.14.1) (4.0.12)\n",
            "Requirement already satisfied: graphql-core<3.3,>=3.1 in /usr/local/lib/python3.12/dist-packages (from graphene<4->mlflow==2.14.1) (3.2.7)\n",
            "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /usr/local/lib/python3.12/dist-packages (from graphene<4->mlflow==2.14.1) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /usr/local/lib/python3.12/dist-packages (from graphene<4->mlflow==2.14.1) (2.9.0.post0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow==2.14.1) (3.23.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow==2.14.1) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow==2.14.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow==2.14.1) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow==2.14.1) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow==2.14.1) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow==2.14.1) (3.2.5)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow==2.14.1) (0.58b0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3->mlflow==2.14.1) (2025.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from querystring-parser<2->mlflow==2.14.1) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow==2.14.1) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow==2.14.1) (3.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow==2.14.1) (2025.10.5)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2->mlflow==2.14.1) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2->mlflow==2.14.1) (3.6.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow==2.14.1) (3.2.4)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow==2.14.1) (5.0.2)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.12/dist-packages (7.5.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install mlflow==2.14.1\n",
        "!pip install pyngrok\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "mlflow_dir = \"/content/drive/MyDrive/Colab Notebooks/ML_flow/mlflow_runs\"  # pick your folder\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Nu9QPAFs4r9",
        "outputId": "4acf9657-8624-4324-fea3-7ebccaf45bd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Kill old servers\n",
        "!pkill -f mlflow\n",
        "\n",
        "# Start MLflow UI/Server with Google Drive as backend store\n",
        "!nohup mlflow ui \\\n",
        "  --backend-store-uri \"file:/content/drive/MyDrive/Colab Notebooks/ML_flow/mlflow_runs\" \\\n",
        "  --default-artifact-root \"file:/content/drive/MyDrive/Colab Notebooks/ML_flow/mlflow_runs\" \\\n",
        "  --host 0.0.0.0 --port 5000 > mlflow_ui.log 2>&1 &\n"
      ],
      "metadata": {
        "id": "BnrbJN98s7eM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Use your ngrok auth token\n",
        "ngrok.set_auth_token(\"35UdMRWoqMHpNBmwoFdo6zUaxGI_3FKaBqxG7Adjt5KJgzLSc\")\n",
        "\n",
        "# Expose MLflow port 5000\n",
        "public_url = ngrok.connect(5000)\n",
        "public_url\n",
        "\n",
        "#mlflow.set_tracking_uri(public_url.public_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUWhn9jps65e",
        "outputId": "0b8abc7a-540b-4635-8519-07f406ee96ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<NgrokTunnel: \"https://ungoaded-dustin-unmimicked.ngrok-free.dev\" -> \"http://localhost:5000\">"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "\n",
        "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")   # local HTTP is enough\n",
        "# OR if you really want, you *can* use public_url.public_url, but not needed\n",
        "# mlflow.set_tracking_uri(public_url.public_url)\n"
      ],
      "metadata": {
        "id": "clL9_LgHs62l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Color            | Meaning                                                 |\n",
        "| ---------------- | ------------------------------------------------------- |\n",
        "| **üî¥ Red**       | Run completed normally but did NOT log a model artifact |\n",
        "| **üü¢ Green**     | Run logged a model artifact                             |\n",
        "| **‚ö†Ô∏è Yellow**    | Appears only when run is *active* (running right now)   |\n",
        "| **‚ùå Error icon** | Only appears if exceptions happened                     |\n"
      ],
      "metadata": {
        "id": "5z-PIx_aBhSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "from datetime import date\n",
        "from dateutil.relativedelta import relativedelta\n",
        "import pprint\n",
        "import pandas_datareader\n",
        "import pandas\n",
        "import requests\n",
        "\n",
        "import pandas_datareader.data as web\n",
        "from scipy.stats import entropy\n",
        "\n",
        "import os\n",
        "import mlflow\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n"
      ],
      "metadata": {
        "id": "kiCppZtot2N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1). Data and Feature Management"
      ],
      "metadata": {
        "id": "5GAuZRf1JIzw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1. bronze-load_raw_data.py"
      ],
      "metadata": {
        "id": "C06SLi_dy0sK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.set_experiment(\"raw_data_ingestion\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpGz6pbts6zM",
        "outputId": "1f20d198-17b5-4012-c365-f867895c176c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/11/17 21:29:07 INFO mlflow.tracking.fluent: Experiment with name 'raw_data_ingestion' does not exist. Creating a new experiment.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Experiment: artifact_location=('file:///content/drive/MyDrive/Colab '\n",
              " 'Notebooks/ML_flow/mlflow_runs/999616519092735634'), creation_time=1763414947254, experiment_id='999616519092735634', last_update_time=1763414947254, lifecycle_stage='active', name='raw_data_ingestion', tags={}>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load_raw_data.py\n",
        "\n",
        "import mlflow\n",
        "import os\n",
        "from datetime import datetime, date\n",
        "from dateutil.relativedelta import relativedelta\n",
        "import yfinance as yf\n",
        "\n",
        "RAW_PATH = \"/content/drive/MyDrive/Colab Notebooks/ML_flow/data/raw/\"\n",
        "os.makedirs(RAW_PATH, exist_ok=True)\n",
        "\n",
        "\n",
        "def safe_today():\n",
        "    system_date = datetime.utcnow().date()\n",
        "    real_today = date.today()\n",
        "\n",
        "    # If system time is ahead (common on some VMs), use real_today\n",
        "    if system_date > real_today:\n",
        "        return real_today\n",
        "    return system_date\n",
        "\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Load Data & Log\n",
        "# ---------------------------\n",
        "with mlflow.start_run(run_name=\"load_raw_data\") as run:\n",
        "\n",
        "    mlflow.set_tag(\"stage\", \"bronze\")\n",
        "    mlflow.set_tag(\"source\", \"Yahoo Finance via yfinance\")\n",
        "    mlflow.set_tag(\"asset\", \"BTC-USD\")\n",
        "\n",
        "    # Date range: past 3 months\n",
        "    end = safe_today()\n",
        "    start = end - relativedelta(months=3)\n",
        "\n",
        "    print(f\"Downloading BTC-USD from {start} to {end} ...\")\n",
        "\n",
        "    # Download using yfinance (reliable)\n",
        "    df = yf.download(\"BTC-USD\", start=start, end=end)\n",
        "\n",
        "    # Log shape\n",
        "    mlflow.log_metric(\"raw_row_count\", len(df))\n",
        "    mlflow.log_metric(\"raw_col_count\", df.shape[1])\n",
        "\n",
        "    # Save CSV\n",
        "    save_path = f\"{RAW_PATH}/data.csv\"\n",
        "    df.to_csv(save_path)\n",
        "\n",
        "    # Log as MLflow artifact\n",
        "    mlflow.log_artifact(save_path)\n",
        "    print(f\"MLflow Experiment ID: {run.info.experiment_id}\")\n",
        "    print(f\"Raw data saved to: {save_path}\")\n",
        "    print(f\"MLflow run ID: {run.info.run_id}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfAiBVQLukCP",
        "outputId": "5ac6a032-2105-439c-f676-826aa4045844"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4244930487.py:14: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  system_date = datetime.utcnow().date()\n",
            "/tmp/ipython-input-4244930487.py:40: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  df = yf.download(\"BTC-USD\", start=start, end=end)\n",
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading BTC-USD from 2025-08-17 to 2025-11-17 ...\n",
            "MLflow Experiment ID: 999616519092735634\n",
            "Raw data saved to: /content/drive/MyDrive/Colab Notebooks/ML_flow/data/raw//data.csv\n",
            "MLflow run ID: 8572ba4e79d7405cbe52149e61f855fa\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbXkIfKE60Ev",
        "outputId": "c0ac22aa-cfac-47bc-badb-cf8b78ef9a03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2. check_verify_data"
      ],
      "metadata": {
        "id": "f4pjKk1f4kBK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check_verify_data.py\n",
        "\n",
        "import mlflow\n",
        "import os\n",
        "import pandas as pd\n",
        "import great_expectations as ge\n"
      ],
      "metadata": {
        "id": "Tq901c4_5TAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "import os\n",
        "import pandas as pd\n",
        "import great_expectations as ge\n",
        "\n",
        "\n",
        "STAGING_PATH = \"/content/drive/MyDrive/Colab Notebooks/ML_flow/data/staging\"\n",
        "os.makedirs(STAGING_PATH, exist_ok=True)\n",
        "\n",
        "\n",
        "def assert_type(df, col, dtype):\n",
        "    if df[col].dtype != dtype:\n",
        "        raise ValueError(f\"Column {col} expected {dtype}, got {df[col].dtype}\")\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "0AY3bU-76KUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check_verify_data.py\n",
        "\n",
        "import mlflow\n",
        "import os\n",
        "import pandas as pd\n",
        "import great_expectations as ge\n",
        "\n",
        "\n",
        "STAGING_PATH = \"/content/drive/MyDrive/Colab Notebooks/ML_flow/data/staging\"\n",
        "os.makedirs(STAGING_PATH, exist_ok=True)\n",
        "\n",
        "\n",
        "def assert_type(df, col, dtype):\n",
        "    if df[col].dtype != dtype:\n",
        "        raise ValueError(f\"Column {col} expected {dtype}, got {df[col].dtype}\")\n",
        "\n",
        "\n",
        "\n",
        "with mlflow.start_run(run_name=\"check_verify_data\") as run:\n",
        "\n",
        "    mlflow.set_tag(\"stage\", \"silver\")\n",
        "    mlflow.set_tag(\"task\", \"data_validation\")\n",
        "\n",
        "    # Load Bronze data\n",
        "\n",
        "    # ---------------------------\n",
        "    # 1. Load raw CSV\n",
        "    # ---------------------------\n",
        "    df_raw = pd.read_csv(RAW_PATH+\"/data.csv\")\n",
        "\n",
        "    # Your raw file has TWO header rows (Ticker, Date, BTC-USD)\n",
        "    # We drop those rows\n",
        "    df = df_raw.iloc[2:].reset_index(drop=True)\n",
        "\n",
        "    # Rename the first column to \"Date\"\n",
        "    df.rename(columns={df.columns[0]: \"Date\"}, inplace=True)\n",
        "\n",
        "    # ---------------------------\n",
        "    # 2. Convert data types\n",
        "    # ---------------------------\n",
        "    # Convert Date to datetime\n",
        "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
        "\n",
        "    # Auto-detect numeric columns (everything except Date)\n",
        "    numeric_cols = df.drop(columns=[\"Date\"], errors=\"ignore\").columns.tolist()\n",
        "\n",
        "    for col in numeric_cols:\n",
        "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "\n",
        "\n",
        "    # -----------------------------------\n",
        "    # SIMPLE DATA VALIDATION (RECOMMENDED)\n",
        "    # -----------------------------------\n",
        "\n",
        "    # Expected numeric columns\n",
        "    numeric_cols = [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"] # 'Adj Close' is often not present for crypto data\n",
        "\n",
        "    # Explicitly convert numeric columns to float, coercing errors\n",
        "    for col in numeric_cols:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "    for col in numeric_cols:\n",
        "        if col not in df.columns:\n",
        "            raise ValueError(f\"Missing required column: {col}\")\n",
        "\n",
        "        if not pd.api.types.is_numeric_dtype(df[col]):\n",
        "            # This check should now pass if conversion was successful\n",
        "            raise TypeError(f\"Column {col} must be numeric after conversion\")\n",
        "\n",
        "        if df[col].isnull().mean() > 0.2:\n",
        "            raise ValueError(f\"Too many nulls in column: {col}\")\n",
        "\n",
        "    # Check date column\n",
        "    if \"Date\" in df.columns:\n",
        "        try:\n",
        "            df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
        "        except:\n",
        "            raise ValueError(\"Invalid Date format\")\n",
        "\n",
        "    mlflow.log_metric(\"validation_success\", 1)\n",
        "\n",
        "    # -----------------------------------\n",
        "    # Cleaning (simple)\n",
        "    # -----------------------------------\n",
        "    df_clean = df.dropna()\n",
        "    mlflow.log_metric(\"cleaned_row_count\", len(df_clean))\n",
        "\n",
        "    # Save staged data\n",
        "    save_path = f\"{STAGING_PATH}/data.csv\"\n",
        "    df_clean.to_csv(save_path, index=False)\n",
        "    mlflow.log_artifact(save_path)\n",
        "\n",
        "    print(\"Staged data saved to:\", save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QBKrkSAyDqx",
        "outputId": "dfd00001-6d09-41a6-d9f0-76496e9ca16f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Staged data saved to: /content/drive/MyDrive/Colab Notebooks/ML_flow/data/staging/data.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3. Gold- feature_set_generation"
      ],
      "metadata": {
        "id": "Zq38_zFr_dvJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAINING_PATH = \"/content/drive/MyDrive/Colab Notebooks/ML_flow/data/training\"\n",
        "os.makedirs(TRAINING_PATH, exist_ok=True)\n",
        "\n",
        "# -------------------------------------\n",
        "# Rolling window implementation\n",
        "# (template from the book ‚Äî unchanged)\n",
        "# -------------------------------------\n",
        "def rolling_window(a, window):\n",
        "    \"\"\"\n",
        "    Takes np.array 'a' and size 'window'\n",
        "    Returns np.array of ordered sequences of size 'window'\n",
        "\n",
        "    Example:\n",
        "    a = [1,2,3,4,5,6], window=4\n",
        "    ‚Üí [[1,2,3,4],\n",
        "       [2,3,4,5],\n",
        "       [3,4,5,6]]\n",
        "    \"\"\"\n",
        "    shape = a.shape[:-1] + (a.shape[-1] - window + 1, window)\n",
        "    strides = a.strides + (a.strides[-1],)\n",
        "    return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)"
      ],
      "metadata": {
        "id": "fCRRcv1J5LmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with mlflow.start_run(run_name=\"generate_feature_set\") as run:\n",
        "\n",
        "    # Metadata\n",
        "    mlflow.set_tag(\"stage\", \"gold\")\n",
        "    mlflow.set_tag(\"description\", \"Generate windowed feature dataset\")\n",
        "\n",
        "    # Create training directory if it doesn't exist\n",
        "\n",
        "\n",
        "    # -------------------------------------\n",
        "    # 1. Load cleaned data\n",
        "    # -------------------------------------\n",
        "    df = pd.read_csv(STAGING_PATH+\"/data.csv\")\n",
        "\n",
        "    # Log input data dimensions\n",
        "    mlflow.log_metric(\"staging_rows\", len(df))\n",
        "    mlflow.log_metric(\"staging_cols\", len(df.columns))\n",
        "\n",
        "    # -------------------------------------\n",
        "    # 2. Feature Engineering\n",
        "    # -------------------------------------\n",
        "    # Price movement label\n",
        "    df[\"delta_pct\"] = (df[\"Close\"] - df[\"Open\"]) / df[\"Open\"]\n",
        "    df[\"going_up\"] = df[\"delta_pct\"].apply(lambda d: 1 if d > 0.00001 else 0)\n",
        "\n",
        "    # Log class counts\n",
        "    up_count = df[\"going_up\"].sum()\n",
        "    down_count = len(df) - up_count\n",
        "    mlflow.log_metric(\"label_up_count\", up_count)\n",
        "    mlflow.log_metric(\"label_down_count\", down_count)\n",
        "\n",
        "    # Convert label column to numpy\n",
        "    series = df[\"going_up\"].to_numpy()\n",
        "\n",
        "    # Window size\n",
        "    WINDOW_SIZE = 15\n",
        "    mlflow.log_param(\"window_size\", WINDOW_SIZE)\n",
        "\n",
        "    # -------------------------------------\n",
        "    # 3. Generate rolling window training data\n",
        "    # -------------------------------------\n",
        "    training_data = rolling_window(series, WINDOW_SIZE)\n",
        "\n",
        "    # Log number of samples produced\n",
        "    mlflow.log_metric(\"training_samples\", len(training_data))\n",
        "\n",
        "\n",
        "    # (a) Sum inside each window (number of upward movements)\n",
        "    window_sums = training_data.sum(axis=1)\n",
        "    mlflow.log_metric(\"window_avg_sum\", window_sums.mean())\n",
        "    mlflow.log_metric(\"window_min_sum\", window_sums.min())\n",
        "    mlflow.log_metric(\"window_max_sum\", window_sums.max())\n",
        "    mlflow.log_metric(\"window_std_sum\", window_sums.std())\n",
        "\n",
        "    # (b) Proportion of 1‚Äôs inside windows\n",
        "    prop_up = window_sums / WINDOW_SIZE\n",
        "    mlflow.log_metric(\"window_avg_up_ratio\", prop_up.mean())\n",
        "\n",
        "    # (c) Transition dynamics\n",
        "    diffs = np.diff(training_data, axis=1)   # shape: (N, WINDOW_SIZE-1)\n",
        "    up_jumps = (diffs == 1).sum()\n",
        "    down_jumps = (diffs == -1).sum()\n",
        "\n",
        "    mlflow.log_metric(\"transitions_up\", int(up_jumps))\n",
        "    mlflow.log_metric(\"transitions_down\", int(down_jumps))\n",
        "    mlflow.log_metric(\"transition_ratio_up_down\",\n",
        "                      float(up_jumps / max(1, down_jumps)))\n",
        "\n",
        "    # (d) Entropy per window (complexity measure)\n",
        "    window_entropy = [entropy([p, 1-p]) for p in prop_up]\n",
        "    mlflow.log_metric(\"window_avg_entropy\", float(np.mean(window_entropy)))\n",
        "\n",
        "\n",
        "\n",
        "    # -------------------------------------\n",
        "    # 4. Save Gold Training dataset\n",
        "    # -------------------------------------\n",
        "    save_path = f\"{TRAINING_PATH}/data.csv\"\n",
        "    pd.DataFrame(training_data).to_csv(save_path, index=False)\n",
        "\n",
        "    # Log artifact\n",
        "    mlflow.log_artifact(save_path)\n",
        "\n",
        "    print(\"Training data generated:\", save_path)\n",
        "    print(\"MLflow Run ID:\", run.info.run_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hQuasqp_vd0",
        "outputId": "ed1b537c-4135-414e-b87b-69c26f812026"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data generated: /content/drive/MyDrive/Colab Notebooks/ML_flow/data/training/data.csv\n",
            "MLflow Run ID: 7e1a673dedf14c27ac02979dc1f8978f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9Waxeoi__c2",
        "outputId": "7a59c318-4c10-4517-ac43-460763f4c4b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 1, 0],\n",
              "       [0, 0, 1, ..., 1, 0, 1],\n",
              "       [0, 1, 0, ..., 0, 1, 1],\n",
              "       ...,\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 0, ..., 0, 0, 1],\n",
              "       [1, 0, 0, ..., 0, 1, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2). Training Models with MLflow"
      ],
      "metadata": {
        "id": "JZfA5OQFI_Bc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "PREDICTION_PATH = \"/content/drive/MyDrive/Colab Notebooks/ML_flow/data/predictions\"\n",
        "os.makedirs(PREDICTION_PATH, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "oX-2l6TJNT7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1. Implementing the training job"
      ],
      "metadata": {
        "id": "buDk3oMUQ8V1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import mlflow\n",
        "import xgboost as xgb\n",
        "import mlflow.xgboost\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def train_test_split_pandas(pandas_df,t_size=0.33,r_tate=42):\n",
        "    X=pandas_df.iloc[:,:-1]\n",
        "    Y=pandas_df.iloc[:,-1]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=t_size, random_state=r_tate)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "\n",
        "\n",
        "THRESHOLD = 0.5\n",
        "\n",
        "mlflow.xgboost.autolog()\n",
        "with mlflow.start_run(run_name=\"train_model\") as run:\n",
        "    mlflow.set_tag(\"mlflow.runName\", \"train_model\")\n",
        "\n",
        "    pandas_df=pd.read_csv(f\"{TRAINING_PATH}/data.csv\", header=None)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split_pandas(pandas_df)\n",
        "\n",
        "    train_data = xgb.DMatrix(X_train, label=y_train)\n",
        "    test_data =  xgb.DMatrix(X_test)\n",
        "\n",
        "    model = xgb.train(dtrain=train_data,params={})\n",
        "\n",
        "    y_probas=model.predict(test_data)\n",
        "    y_preds = [1 if  y_proba > THRESHOLD else 0 for y_proba in y_probas]\n",
        "\n",
        "    test_prediction_results = pd.DataFrame(data={'y_pred':y_preds,'y_test':y_test})\n",
        "\n",
        "    result = test_prediction_results\n",
        "\n",
        "    # Use the defined PREDICTION_PATH\n",
        "    prediction_file_path = f\"{PREDICTION_PATH}/test_predictions.csv\"\n",
        "    result.to_csv(prediction_file_path)\n",
        "    mlflow.log_artifact(prediction_file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlPfTL_zI3VK",
        "outputId": "eec587ed-e437-4f7f-e63a-4635b1391557"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/11/17 23:56:48 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of xgboost. If you encounter errors during autologging, try upgrading / downgrading xgboost to a supported version, or try upgrading MLflow.\n",
            "2025/11/17 23:56:49 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:406: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "2025/11/17 23:56:49 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/usr/local/lib/python3.12/dist-packages/mlflow/models/model.py:321: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\"\n",
            "2025/11/17 23:56:49 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/usr/local/lib/python3.12/dist-packages/mlflow/xgboost/__init__.py:165: UserWarning: [23:56:49] WARNING: /workspace/src/c_api/c_api.cc:1575: Saving model in the UBJSON format as default.  You can use a file extension: `json` or `ubj` to choose between formats.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2. Evaluating the model"
      ],
      "metadata": {
        "id": "Ew_OcYVuJjhK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import mlflow\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import  \\\n",
        "    classification_report, \\\n",
        "    confusion_matrix, \\\n",
        "    accuracy_score, \\\n",
        "    auc, \\\n",
        "    average_precision_score, \\\n",
        "    balanced_accuracy_score, \\\n",
        "    f1_score, \\\n",
        "    fbeta_score, \\\n",
        "    hamming_loss, \\\n",
        "    jaccard_score, \\\n",
        "    log_loss, \\\n",
        "    matthews_corrcoef, \\\n",
        "    precision_score, \\\n",
        "    recall_score, \\\n",
        "    zero_one_loss\n",
        "\n",
        "def clean_classification_df(df):\n",
        "    \"\"\"\n",
        "    Fixes y_pred and y_test for classification metrics.\n",
        "    Ensures:\n",
        "        - both columns are numeric\n",
        "        - both columns are integers\n",
        "        - both columns are binary (0/1)\n",
        "    \"\"\"\n",
        "    # Convert to numeric\n",
        "    df[\"y_pred\"] = pd.to_numeric(df[\"y_pred\"], errors=\"coerce\")\n",
        "    df[\"y_test\"] = pd.to_numeric(df[\"y_test\"], errors=\"coerce\")\n",
        "\n",
        "    # Round predictions and convert to int\n",
        "    df[\"y_pred\"] = df[\"y_pred\"].round().astype(int)\n",
        "\n",
        "    # Fix labels: anything > 1 becomes 1, anything < 0 becomes 0\n",
        "    df[\"y_test\"] = df[\"y_test\"].clip(lower=0, upper=1).astype(int)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def classification_metrics(df:None):\n",
        "    metrics={}\n",
        "    metrics[\"accuracy_score\"]=accuracy_score(df[\"y_pred\"], df[\"y_test\"]  )\n",
        "    metrics[\"average_precision_score\"]=average_precision_score( df[\"y_pred\"], df[\"y_test\"]  )\n",
        "    metrics[\"f1_score\"]=f1_score( df[\"y_pred\"], df[\"y_test\"]  )\n",
        "    metrics[\"jaccard_score\"]=jaccard_score( df[\"y_pred\"], df[\"y_test\"]  )\n",
        "    metrics[\"log_loss\"]=log_loss( df[\"y_pred\"], df[\"y_test\"]  )\n",
        "    metrics[\"matthews_corrcoef\"]=matthews_corrcoef( df[\"y_pred\"], df[\"y_test\"]  )\n",
        "    metrics[\"precision_score\"]=precision_score( df[\"y_pred\"], df[\"y_test\"]  )\n",
        "    metrics[\"recall_score\"]=recall_score( df[\"y_pred\"], df[\"y_test\"]  )\n",
        "    metrics[\"zero_one_loss\"]=zero_one_loss( df[\"y_pred\"], df[\"y_test\"]  )\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "7Z4x6jcqOTac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with mlflow.start_run(run_name=\"evaluate_model\") as run:\n",
        "    mlflow.set_tag(\"mlflow.runName\", \"evaluate_model\")\n",
        "    df=pd.read_csv(f\"{PREDICTION_PATH}/test_predictions.csv\")\n",
        "    df= clean_classification_df(df)\n",
        "    metrics = classification_metrics(df)\n",
        "    mlflow.log_metrics(metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3IgftoROVXp",
        "outputId": "013aea80-d6c0-43db-9824-fae5634d26f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparing different models"
      ],
      "metadata": {
        "id": "akOA6sb7f4vV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tuning your model with hyperparameter optimization"
      ],
      "metadata": {
        "id": "J6lpcDWJf8dD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3. Deploying the model in the Model Registry\n",
        "\n",
        "MLflow encourages registering from inside or immediately after your training run."
      ],
      "metadata": {
        "id": "_JKq42djQ0KO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "\n",
        "# Put your latest training RUN_ID here (manually or via automation)\n",
        "RUN_ID = \"e35d976fdad5404388af86813e92b240\"\n",
        "MODEL_NAME = \"training-model-psystock\"\n",
        "MODEL_URI = f\"runs:/{RUN_ID}/model\"\n",
        "\n",
        "mlflow.set_experiment(\"model_register_pipeline\")\n",
        "\n",
        "with mlflow.start_run(run_name=\"register_model\") as run:\n",
        "\n",
        "    mlflow.set_tag(\"stage\", \"register\")\n",
        "    mlflow.set_tag(\"source_run_id\", RUN_ID)\n",
        "\n",
        "    result = mlflow.register_model(\n",
        "        model_uri=MODEL_URI,\n",
        "        name=MODEL_NAME\n",
        "    )\n",
        "\n",
        "    print(\"Registered model:\", result.name)\n",
        "    print(\"Version:\", result.version)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYYuoG5VOcZY",
        "outputId": "7775dd40-a444-4f12-e63b-7708dc4bdd7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/11/18 00:41:21 INFO mlflow.tracking.fluent: Experiment with name 'model_register_pipeline' does not exist. Creating a new experiment.\n",
            "Successfully registered model 'training-model-psystock'.\n",
            "2025/11/18 00:41:21 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: training-model-psystock, version 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Registered model: training-model-psystock\n",
            "Version: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Created version '1' of model 'training-model-psystock'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Other registry strategy\n",
        "- Auto-register only if model meets thresholds\n",
        "```python\n",
        "if f1 > 0.70 and accuracy > 0.60:\n",
        "    mlflow.register_model(...)\n",
        "else:\n",
        "    print(\"Model rejected ‚Äî does not meet performance threshold\")\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "CFVLznqgal9_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bLcVqs3Xap1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "\n",
        "mlflow_model = mlflow.pyfunc.load_model(\"models:/training-model-psystock/1\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXwhHxuGPhXQ",
        "outputId": "9f940a38-bcf2-43fe-f599-f7236b40ba7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mlflow/xgboost/__init__.py:299: UserWarning: [00:59:38] WARNING: /workspace/src/c_api/c_api.cc:1511: Unknown file format: `xgb`. Using UBJSON (`ubj`) as a guess.\n",
            "  model.load_model(xgb_model_path)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3). Monitoring data drift and model performance"
      ],
      "metadata": {
        "id": "seuQanAMo2Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1. Monitoring data drift\n",
        "\n",
        "- drift library (like Evidently) to compute drift\n",
        "- use MLflow to track + store those drift reports and metrics over time"
      ],
      "metadata": {
        "id": "W_GZKSPbo-Zd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Corrected URL for the raw CSV content\n",
        "url = \"https://raw.githubusercontent.com/PacktPublishing/Machine-Learning-Engineering-with-MLflow/master/Chapter11/model_performance_drifts/training_data.csv\"\n",
        "\n",
        "reference_data = pd.read_csv(url,\n",
        "    header=None,\n",
        "    names=[ \"day{}\".format(i) for i in range(0,14) ] )\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/PacktPublishing/Machine-Learning-Engineering-with-MLflow/master/Chapter11/model_performance_drifts/to_score_input_data.csv\"\n",
        "\n",
        "latest_input_data = pd.read_csv(url,\n",
        "    header=None,\n",
        "    names=[ \"day{}\".format(i) for i in range(0,14) ] )"
      ],
      "metadata": {
        "id": "pryJ456ieW_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install alibi-detect\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xS9hq9VV8xih",
        "outputId": "406f65f2-193d-40d8-f946-7684aba09c4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: alibi-detect in /usr/local/lib/python3.12/dist-packages (0.12.0)\n",
            "Requirement already satisfied: matplotlib<4.0.0,>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from alibi-detect) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.16.2 in /usr/local/lib/python3.12/dist-packages (from alibi-detect) (1.26.4)\n",
            "Requirement already satisfied: pandas<3.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from alibi-detect) (2.2.2)\n",
            "Requirement already satisfied: Pillow<11.0.0,>=5.4.1 in /usr/local/lib/python3.12/dist-packages (from alibi-detect) (10.4.0)\n",
            "Requirement already satisfied: opencv-python<5.0.0,>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from alibi-detect) (4.11.0.86)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from alibi-detect) (1.16.3)\n",
            "Requirement already satisfied: scikit-image<0.23,>=0.19 in /usr/local/lib/python3.12/dist-packages (from alibi-detect) (0.22.0)\n",
            "Requirement already satisfied: scikit-learn<2.0.0,>=0.20.2 in /usr/local/lib/python3.12/dist-packages (from alibi-detect) (1.6.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from alibi-detect) (4.57.1)\n",
            "Requirement already satisfied: dill<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from alibi-detect) (0.3.8)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.28.1 in /usr/local/lib/python3.12/dist-packages (from alibi-detect) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from alibi-detect) (2.32.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from alibi-detect) (1.10.24)\n",
            "Requirement already satisfied: toml<1.0.0,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from alibi-detect) (0.10.2)\n",
            "Requirement already satisfied: catalogue<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from alibi-detect) (2.0.10)\n",
            "Requirement already satisfied: numba!=0.54.0,<0.60.0,>=0.50.0 in /usr/local/lib/python3.12/dist-packages (from alibi-detect) (0.59.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from alibi-detect) (4.15.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect) (2.9.0.post0)\n",
            "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba!=0.54.0,<0.60.0,>=0.50.0->alibi-detect) (0.42.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0.0,>=1.0.0->alibi-detect) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0.0,>=1.0.0->alibi-detect) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.21.0->alibi-detect) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.21.0->alibi-detect) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.21.0->alibi-detect) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.21.0->alibi-detect) (2025.10.5)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.12/dist-packages (from scikit-image<0.23,>=0.19->alibi-detect) (3.5)\n",
            "Requirement already satisfied: imageio>=2.27 in /usr/local/lib/python3.12/dist-packages (from scikit-image<0.23,>=0.19->alibi-detect) (2.37.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image<0.23,>=0.19->alibi-detect) (2025.10.16)\n",
            "Requirement already satisfied: lazy_loader>=0.3 in /usr/local/lib/python3.12/dist-packages (from scikit-image<0.23,>=0.19->alibi-detect) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2.0.0,>=0.20.2->alibi-detect) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2.0.0,>=0.20.2->alibi-detect) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.0.0->alibi-detect) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.0.0->alibi-detect) (0.36.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.0.0->alibi-detect) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.0.0->alibi-detect) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.0.0->alibi-detect) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.0.0->alibi-detect) (0.6.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers<5.0.0,>=4.0.0->alibi-detect) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers<5.0.0,>=4.0.0->alibi-detect) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib<4.0.0,>=3.0.0->alibi-detect) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EXPERIMENT_NAME = \"reports_data_drift\"\n",
        "mlflow.set_experiment(EXPERIMENT_NAME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fnsmNBQ_z55",
        "outputId": "50940250-b489-40fa-bd65-6fc4a1f7c9a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/11/18 03:25:58 INFO mlflow.tracking.fluent: Experiment with name 'reports_data_drift' does not exist. Creating a new experiment.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Experiment: artifact_location=('file:///content/drive/MyDrive/Colab '\n",
              " 'Notebooks/ML_flow/mlflow_runs/563996555121758798'), creation_time=1763436359026, experiment_id='563996555121758798', last_update_time=1763436359026, lifecycle_stage='active', name='reports_data_drift', tags={}>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from alibi_detect.cd import KSDrift\n",
        "ref = reference_data.to_numpy()\n",
        "new = latest_input_data.to_numpy()\n",
        "\n",
        "cd = KSDrift(ref, p_val=0.05)\n",
        "preds = cd.predict(new)   # dict with 'data' and 'meta'"
      ],
      "metadata": {
        "id": "9uLz5_ZX9aTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tb813oP3AjdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QwJpwF8cAjOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "EXPERIMENT_PATH = \"/content/drive/MyDrive/Colab Notebooks/ML_flow//reports_data_drift//\"\n",
        "os.makedirs(EXPERIMENT_PATH, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "jOlzK8EVACZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "\n",
        "from alibi_detect.cd import KSDrift  # univariate drift detector\n",
        "from alibi_detect.utils.saving import save_detector\n",
        "\n",
        "with mlflow.start_run(run_name=\"alibi_data_drift\"):\n",
        "\n",
        "    mlflow.set_tag(\"stage\", \"drift_monitoring\")\n",
        "    mlflow.set_tag(\"drift_method\", \"alibi_ks\")\n",
        "\n",
        "    preds = cd.predict(new)\n",
        "\n",
        "    # Quick summary metrics\n",
        "    is_drift = int(preds[\"data\"][\"is_drift\"])          # 0 or 1 (overall drift flag)\n",
        "    p_vals = preds[\"data\"][\"p_val\"]                    # list of length 14\n",
        "    threshold = preds[\"data\"][\"threshold\"]\n",
        "\n",
        "    n_drifted_features = int(np.sum(np.array(p_vals) < threshold))\n",
        "    share_drifted = n_drifted_features / len(p_vals)\n",
        "\n",
        "    # Log metrics to MLflow\n",
        "    mlflow.log_metric(\"is_drift\", is_drift)\n",
        "    mlflow.log_metric(\"n_drifted_features\", n_drifted_features)\n",
        "    mlflow.log_metric(\"share_drifted\", share_drifted)\n",
        "\n",
        "    # You can also log per-feature p-values if you like:\n",
        "    for i, p in enumerate(p_vals):\n",
        "        mlflow.log_metric(f\"feature_day{i}_pvalue\", float(p))\n",
        "\n",
        "\n",
        "\n",
        "    # -------------------------\n",
        "    # 6. Log folder to MLflow\n",
        "    # -------------------------\n",
        "    mlflow.log_artifacts(EXPERIMENT_PATH)\n",
        "\n",
        "    print(\"Drift report saved and logged to MLflow.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiytPFUm9i_y",
        "outputId": "e76a8f7c-68de-4424-bde9-6e47f458b8b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drift report saved and logged to MLflow.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2. Monitoring target drift"
      ],
      "metadata": {
        "id": "gZWMFUKQpBkd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VaK6eJ5ZpD37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3. Monitoring model drift"
      ],
      "metadata": {
        "id": "fD8Yhvv8pEau"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GHuTOOKFpF-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.4. Infrastructure monitoring and alerting"
      ],
      "metadata": {
        "id": "cBeB_CdspJam"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Akc-0_xdpKi3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}